import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

# Load dataset and model once when the server starts
data = pd.read_csv("data/suppliers.csv")
data.fillna("", inplace=True)
model = SentenceTransformer("all-MiniLM-L6-v2")

def find_matches(query, k=5):
    # Load the index generated by embedder.py
    index = faiss.read_index("model/company.index")
    
    # Convert user query to vector
    q_vector = model.encode([query])
    distances, indices = index.search(np.array(q_vector).astype('float32'), k)

    results = []
    for pos, i in enumerate(indices[0]):
        # Prevent errors if index is out of bounds
        if i < 0 or i >= len(data):
            continue
            
        row = data.iloc[i]
        
        # Calculate a human-readable match score (0 to 100)
        score = round(100 - (distances[0][pos] * 10), 2)
        score = max(0, score) 

        results.append({
            "company": row["company"],
            "product": row["product"],
            "category": row["category"],
            "location": row["location"],
            "match_score": score,
            "reason": "Matched using semantic AI search."
        })

    return results